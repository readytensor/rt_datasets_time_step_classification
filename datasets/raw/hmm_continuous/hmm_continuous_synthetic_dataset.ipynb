{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a8ab70f",
   "metadata": {},
   "source": [
    "# HMM Continuous Timeseries Dataset\n",
    "\n",
    "This synthetic dataset is generated using a Hidden Markov Model (HMM) with continuous valued observations. Each sample in the dataset is a multivariate timeseries with a variable length. The dataset includes an identifier for each sample, a set of continuous observations for each timestep, and a corresponding state label for each timestep.\n",
    "\n",
    "## Dataset Generation Process\n",
    "\n",
    "1. **HMM Parameters**:\n",
    "   - **Number of States (M)**: The HMM has a specified number of states.\n",
    "   - **Number of Gaussians (K)**: Each state is modeled using a Gaussian Mixture Model (GMM) with a specified number of Gaussians.\n",
    "   - **Dimensions of Observations (D)**: Each observation at a timestep is a D-dimensional vector.\n",
    "\n",
    "2. **State Transition Matrix (A)**:\n",
    "   - The transition probabilities between states are defined by a matrix where the probability of staying in the same state is randomly chosen between a minimum and maximum value for each state.\n",
    "   - The remaining probability is evenly distributed among transitions to other states.\n",
    "\n",
    "3. **Initial State Distribution (pi)**:\n",
    "   - The initial state distribution is uniform, where each state has an equal probability.\n",
    "\n",
    "4. **GMM Parameters**:\n",
    "   - **Mixture Proportions (R)**: The proportions for each Gaussian in the GMM are drawn from a Dirichlet distribution.\n",
    "   - **Means (mu)**: The means of the Gaussians are randomly initialized.\n",
    "   - **Covariances (sigma)**: The covariances of the Gaussians are diagonal matrices with random values.\n",
    "\n",
    "5. **Observation Generation**:\n",
    "   - States for each timestep are generated according to the HMM's transition probabilities.\n",
    "   - Observations are generated from the GMM corresponding to the current state.\n",
    "\n",
    "## Dataset Structure\n",
    "\n",
    "- **Sample ID**: A unique identifier for each sample.\n",
    "- **Variable Length Timeseries**: Each sample is a timeseries with a length randomly chosen between specified minimum and maximum values.\n",
    "- **Observations**: Each observation is a D-dimensional vector of continuous values.\n",
    "- **State Labels**: Each timestep in the timeseries has a corresponding state label.\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "The HMM Continuous Timeseries Dataset presents a challenging task for timeseries annotation algorithms, where the goal is to accurately classify each timestep within the sequences based on the hidden states of the HMM. The variable length of the samples adds complexity, making it an excellent dataset for advanced timeseries analysis techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a6cd453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d1291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"hmm_continuous\"\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe4fdd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'./../../processed/{dataset_name}/'\n",
    "outp_fname = os.path.join(output_dir, f'{dataset_name}.csv')\n",
    "train_outp_fname = os.path.join(output_dir, f'{dataset_name}_train.csv')\n",
    "test_outp_fname = os.path.join(output_dir, f'{dataset_name}_test.csv')\n",
    "test_key_outp_fname = os.path.join(output_dir, f'{dataset_name}_test_key.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389fa395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_hmm_parameters(M: int, K: int, D: int, min_stay_prob: float, max_stay_prob: float):\n",
    "    \"\"\"\n",
    "    Generate Hidden Markov Model (HMM) parameters.\n",
    "\n",
    "    Args:\n",
    "        M (int): Number of states.\n",
    "        K (int): Number of Gaussians in the Gaussian Mixture Model (GMM).\n",
    "        D (int): Number of dimensions in the observation.\n",
    "        min_stay_prob (float): Minimum probability of staying in the same state.\n",
    "        max_stay_prob (float): Maximum probability of staying in the same state.\n",
    "\n",
    "    Returns:\n",
    "        pi (np.ndarray): Initial state distribution. Shape is (M,).\n",
    "        A (np.ndarray): State transition matrix. Shape is (M, M).\n",
    "        R (np.ndarray): Mixture of proportions. Shape is (M, K).\n",
    "        mu (np.ndarray): Means of the Gaussians. Shape is (M, K, D).\n",
    "        sigma (np.ndarray): Covariances of the Gaussians. Shape is (M, K, D, D).\n",
    "    \"\"\"\n",
    "    pi = np.ones(M) / M # initial state distribution (uniform)\n",
    "    \n",
    "    A = np.zeros((M, M))\n",
    "    for i in range(M):\n",
    "        stay_prob = np.random.uniform(min_stay_prob, max_stay_prob)\n",
    "        A[i, :] += (1 - stay_prob) / (M - 1)\n",
    "        A[i, i] = stay_prob # overwrite diagonals\n",
    "\n",
    "    \n",
    "    \n",
    "    R = np.random.dirichlet(np.ones(K), size=M)\n",
    "    \n",
    "    mu = np.random.randn(M, K, D)\n",
    "    \n",
    "    sigma = np.zeros((M, K, D, D))\n",
    "    for m in range(M):\n",
    "        for k in range(K):\n",
    "            sigma[m, k, :, :] = np.diag(np.random.rand(D))\n",
    "    return pi, A, R, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7623ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hmm_samples(\n",
    "    N: int,\n",
    "    T: int,\n",
    "    pi: np.ndarray,\n",
    "    A: np.ndarray,\n",
    "    R: np.ndarray,\n",
    "    mu: np.ndarray,\n",
    "    sigma: np.ndarray,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate dataset from the Hidden Markov Model (HMM).\n",
    "\n",
    "    Args:\n",
    "        N (int): Number of samples to generate.\n",
    "        T (int): Length of each sample.\n",
    "        pi (np.ndarray): Initial state distribution. Shape is (M,).\n",
    "        A (np.ndarray): State transition matrix. Shape is (M, M).\n",
    "        R (np.ndarray): Mixture of proportions. Shape is (M, K).\n",
    "        mu (np.ndarray): Means of the Gaussians. Shape is (M, K, D).\n",
    "        sigma (np.ndarray): Covariances of the Gaussians. Shape is (M, K, D, D).\n",
    "        \n",
    "        where\n",
    "            M: number of states\n",
    "            K: number of Gaussians in the GMM\n",
    "            D: number of dimensions in the observation\n",
    "\n",
    "    Returns:\n",
    "        observations (np.ndarray): Generated observations. Shape is (N, T, D).\n",
    "        labels (np.ndarray): State labels for each timestep. Shape is (N, T).\n",
    "    \"\"\"\n",
    "    M, K, D = mu.shape\n",
    "    observations = np.zeros((N, T, D))\n",
    "    labels = np.zeros((N, T), dtype=int)\n",
    "    \n",
    "    for n in range(N):\n",
    "        states = np.zeros(T, dtype=int)\n",
    "        obs = np.zeros((T, D))\n",
    "        # starting state\n",
    "        states[0] = np.random.choice(M, p=pi)\n",
    "        \n",
    "        # rest of the states over the sequence\n",
    "        for t in range(1, T):\n",
    "            states[t] = np.random.choice(M, p=A[states[t-1]])\n",
    "        \n",
    "        # observations over the sequence\n",
    "        for t in range(T):\n",
    "            state = states[t]\n",
    "            component = np.random.choice(K, p=R[state])\n",
    "            obs[t] = np.random.multivariate_normal(mu[state, component], sigma[state, component])\n",
    "        \n",
    "        observations[n] = obs\n",
    "        labels[n] = states\n",
    "        \n",
    "        if n % 100 == 0 and n > 0:\n",
    "            print(f\"Generated {n} samples...\")\n",
    "    \n",
    "    print(\"Done generating samples.\")\n",
    "    return observations, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65865540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_variable_length(\n",
    "        observations: np.ndarray,\n",
    "        labels: np.ndarray,\n",
    "        min_len: int,\n",
    "        max_len: int\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Adjust samples and labels to have variable lengths.\n",
    "\n",
    "    Args:\n",
    "        observations (np.ndarray): Generated observations. Shape is (N, T, D).\n",
    "        labels (np.ndarray): State labels for each timestep. Shape is (N, T).\n",
    "        min_len (int): Minimum length of the samples.\n",
    "        max_len (int): Maximum length of the samples.\n",
    "\n",
    "    Returns:\n",
    "        var_len_observations (list of np.ndarray): List of observations with variable lengths.\n",
    "        var_len_labels (list of np.ndarray): List of labels with variable lengths.\n",
    "    \"\"\"\n",
    "    N, T, D = observations.shape\n",
    "    var_len_observations = []\n",
    "    var_len_labels = []\n",
    "\n",
    "    for i in range(N):\n",
    "        length = np.random.randint(min_len, max_len + 1)\n",
    "        if length > T:\n",
    "            raise ValueError(\n",
    "                f\"Maximum length {max_len} cannot be greater than the original length {T}\"\n",
    "            )\n",
    "        start_idx = np.random.randint(0, T - length + 1)\n",
    "        var_len_observations.append(observations[i, start_idx:start_idx + length, :])\n",
    "        var_len_labels.append(labels[i, start_idx:start_idx + length])\n",
    "    \n",
    "    return var_len_observations, var_len_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c6a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(observations: list, labels: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert the variable length observations and labels to a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        observations (list of np.ndarray): List of observations with variable lengths.\n",
    "        labels (list of np.ndarray): List of labels with variable lengths.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the data with columns for sample_id, label,\n",
    "                      and observation dimensions.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i, (obs, lbl) in enumerate(zip(observations, labels)):\n",
    "        for obs_t, lbl_t in zip(obs, lbl):\n",
    "            row = {\"sample_id\": i, \"label\": int(lbl_t)}\n",
    "            row.update({\n",
    "                f\"observation_dim_{d+1}\": float(obs_t[d]) for d in range(obs.shape[1])\n",
    "            })\n",
    "            data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fedd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hmm_dataset(\n",
    "        N: int,\n",
    "        min_seq_len: int,\n",
    "        max_seq_len: int,\n",
    "        M: int,\n",
    "        K: int,\n",
    "        D: int,\n",
    "        min_stay_prob: float,\n",
    "        max_stay_prob: float\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate HMM dataset with variable length sequences and return as pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        N (int): Number of samples to generate.\n",
    "        min_seq_len (int): Minimum length of the sequences. Must be >= 10\n",
    "        max_seq_len (int): Maximum length of the sequences.\n",
    "        M (int): Number of states.\n",
    "        K (int): Number of Gaussians in the Gaussian Mixture Model (GMM).\n",
    "        D (int): Number of dimensions in the observation.\n",
    "        min_stay_prob (float): Minimum probability of staying in the same state.\n",
    "        max_stay_prob (float): Maximum probability of staying in the same state.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the generated dataset.\n",
    "    \"\"\"\n",
    "    pi, A, R, mu, sigma = generate_hmm_parameters(M, K, D, min_stay_prob, max_stay_prob)\n",
    "    assert min_seq_len >= 10, \"Minimum sequence length should be >= 10\"\n",
    "    assert min_seq_len <= max_seq_len, \"Minimum sequence length cannot be greater than maximum sequence length\"\n",
    "    observations, labels = generate_hmm_samples(\n",
    "        N=N,\n",
    "        T=max_seq_len,\n",
    "        pi=pi,\n",
    "        A=A,\n",
    "        R=R,\n",
    "        mu=mu,\n",
    "        sigma=sigma,\n",
    "    )\n",
    "    var_len_observations, var_len_labels = adjust_variable_length(observations, labels, min_seq_len, max_seq_len)\n",
    "    df = convert_to_dataframe(var_len_observations, var_len_labels)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac93b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=888):\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "085c9a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 samples...\n",
      "Generated 200 samples...\n",
      "Done generating samples.\n"
     ]
    }
   ],
   "source": [
    "N = 300\n",
    "min_seq_len = 50\n",
    "max_seq_len = N\n",
    "# number of states\n",
    "M = 4\n",
    "# number of Gaussians\n",
    "K = 5\n",
    "# dimensionality of data\n",
    "D = 3\n",
    "min_stay_prob = 0.8\n",
    "max_stay_prob = 0.99\n",
    "\n",
    "set_seeds(1)\n",
    "data = generate_hmm_dataset(\n",
    "    N=N,\n",
    "    min_seq_len=min_seq_len,\n",
    "    max_seq_len=max_seq_len,\n",
    "    M=M,\n",
    "    K=K,\n",
    "    D=D,\n",
    "    min_stay_prob=min_stay_prob,\n",
    "    max_stay_prob=max_stay_prob,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d650da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51534, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "868fe20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>label</th>\n",
       "      <th>observation_dim_1</th>\n",
       "      <th>observation_dim_2</th>\n",
       "      <th>observation_dim_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323794</td>\n",
       "      <td>-1.134339</td>\n",
       "      <td>-0.988766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.673589</td>\n",
       "      <td>0.291930</td>\n",
       "      <td>-1.163936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.141649</td>\n",
       "      <td>2.867647</td>\n",
       "      <td>1.001803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100120</td>\n",
       "      <td>0.096912</td>\n",
       "      <td>0.706180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536475</td>\n",
       "      <td>2.487519</td>\n",
       "      <td>0.107215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  label  observation_dim_1  observation_dim_2  observation_dim_3\n",
       "0          0      1           0.323794          -1.134339          -0.988766\n",
       "1          0      1          -0.673589           0.291930          -1.163936\n",
       "2          0      1           0.141649           2.867647           1.001803\n",
       "3          0      1           0.100120           0.096912           0.706180\n",
       "4          0      1           0.536475           2.487519           0.107215"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b6b22",
   "metadata": {},
   "source": [
    "## Adding time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1715e193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>label</th>\n",
       "      <th>observation_dim_1</th>\n",
       "      <th>observation_dim_2</th>\n",
       "      <th>observation_dim_3</th>\n",
       "      <th>timestep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323794</td>\n",
       "      <td>-1.134339</td>\n",
       "      <td>-0.988766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.673589</td>\n",
       "      <td>0.291930</td>\n",
       "      <td>-1.163936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.141649</td>\n",
       "      <td>2.867647</td>\n",
       "      <td>1.001803</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100120</td>\n",
       "      <td>0.096912</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536475</td>\n",
       "      <td>2.487519</td>\n",
       "      <td>0.107215</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  label  observation_dim_1  observation_dim_2  observation_dim_3  \\\n",
       "0          0      1           0.323794          -1.134339          -0.988766   \n",
       "1          0      1          -0.673589           0.291930          -1.163936   \n",
       "2          0      1           0.141649           2.867647           1.001803   \n",
       "3          0      1           0.100120           0.096912           0.706180   \n",
       "4          0      1           0.536475           2.487519           0.107215   \n",
       "\n",
       "   timestep  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  \n",
       "3         3  \n",
       "4         4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = data.groupby(\"sample_id\")\n",
    "with_time = []\n",
    "for i, group in grouped:\n",
    "    group['timestep'] = list(range(len(group)))\n",
    "    with_time.append(group)\n",
    "\n",
    "data = pd.concat(with_time)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f1e05",
   "metadata": {},
   "source": [
    "# Save Main Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1cebe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "data.to_csv(outp_fname, index=False, float_format=\"%.4f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e5c28",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "417ab7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51534, 6) (40493, 6) (11041, 5) (11041, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_by_sample_id(data: pd.DataFrame, test_size: float, random_state: int = None):\n",
    "    \"\"\"\n",
    "    Split the data into train and test sets by sample_id.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The dataset containing sample_id, label, and observation dimensions.\n",
    "        test_size (float): The proportion of the dataset to include in the test split.\n",
    "        random_state (int, optional): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        train_df (pd.DataFrame): The training data.\n",
    "        test_df (pd.DataFrame): The testing data.\n",
    "        test_keys (pd.DataFrame): The testing keys containing sample_id and label.\n",
    "    \"\"\"\n",
    "    # Get unique sample IDs\n",
    "    unique_ids = data['sample_id'].unique()\n",
    "\n",
    "    # Split the sample IDs into train and test sets\n",
    "    train_ids, test_ids = train_test_split(unique_ids, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Initialize lists for storing the split data\n",
    "    train_data, test_data, test_keys = [], [], []\n",
    "\n",
    "    # Group the data by sample_id\n",
    "    grouped = data.groupby('sample_id')\n",
    "\n",
    "    # Assign each group to either train or test based on the split\n",
    "    for sample_id, group in grouped:\n",
    "        if sample_id in train_ids:\n",
    "            train_data.append(group)\n",
    "        else:\n",
    "            test_key = group[['sample_id', 'timestep', 'label']].reset_index(drop=True)\n",
    "            test_df = group.drop(columns=['label']).reset_index(drop=True)\n",
    "            test_data.append(test_df)\n",
    "            test_keys.append(test_key)\n",
    "\n",
    "    # Concatenate the data into final DataFrames\n",
    "    train_df = pd.concat(train_data).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_data).reset_index(drop=True)\n",
    "    test_keys = pd.concat(test_keys).reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df, test_keys\n",
    "\n",
    "# Example usage:\n",
    "# df = generate_and_save_hmm_dataset(100, 50, 100, 3, 2, 2, 0.7, 0.9, seed=42)\n",
    "train_df, test_df, test_keys = split_by_sample_id(data, test_size=test_size, random_state=42)\n",
    "\n",
    "print(data.shape, train_df.shape, test_df.shape, test_keys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e32f719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(train_outp_fname, index=False, float_format=\"%.4f\")\n",
    "test_df.to_csv(test_outp_fname, index=False, float_format=\"%.4f\")\n",
    "test_keys.to_csv(test_key_outp_fname, index=False, float_format=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f16e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
