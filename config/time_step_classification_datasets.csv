model_category,dataset_num,name,title,description,frequency,target_name,target_description,use_dataset,is_smoke_test,encoding
time_step_classification,1,hmm_continuous,hmm_continuous,"This synthetic dataset is generated using a Hidden Markov Model (HMM) with continuous valued observations. Each sample in the dataset is a multivariate timeseries with a variable length. The dataset includes an identifier for each sample, a set of continuous observations for each timestep, and a corresponding state label for each timestep. The HMM Continuous Timeseries Dataset presents a challenging task for time step classification algorithms, where the goal is to accurately classify each timestep within the sequences based on the hidden states of the HMM. ",OTHER,label,Label for each time step in the sample,1,0,utf-8
time_step_classification,2,occupancy_detection,RoomOccupanyDetection,"Experimental data used for binary classification (room occupancy) from Temperature, Humidity, Light and CO2. Ground-truth occupancy was obtained from time stamped pictures that were taken every minute. Reference: Luis M. Candanedo, Véronique Feldheim. Energy and Buildings. Volume 112, 15 January 2016, Pages 28-39. Source: https://github.com/LuisM78/Occupancy-detection-data",SECONDLY,Occupancy,"0 for not occupied, 1 for occupied status",1,0,utf-8
time_step_classification,3,har70plus,HAR70+,The Human Activity Recognition 70+ (HAR70+) dataset is a professionally-annotated dataset containing 18 fit-to-frail older-adult subjects (70-95 years old) wearing two 3-axial accelerometers for around 40 minutes during a semi-structured free-living protocol. The sensors were attached to the right thigh and lower back. The purpose was to train machine learning models for human activity recognition on professionally-annotated accelerometer data of fit-to-frail older adults. Source: https://archive.ics.uci.edu/dataset/780/har70,OTHER,label,"Activity performed by the subject (1: walking  3: shuffling 4: stairs (ascending) 5: stairs (descending) 6: standing 7: sitting	8: lying)",1,0,utf-8
time_step_classification,4,eeg_eye_state,EEG Eye State,"The EEG Eye State Dataset consists of 14 EEG values and an additional value indicating the eye state. The data is derived from a continuous EEG measurement recorded using the Emotiv EEG Neuroheadset over a duration of 117 seconds. The eye state was detected via a camera during the EEG measurement and was manually added to the file after analyzing the video frames. A value of '1' indicates the eye-closed state, while '0' indicates the eye-open state. The dataset values are in chronological order, with the earliest measurement at the top. This dataset is particularly useful for time step classification tasks, aiming to classify the eye state based on the EEG values. Source: https://archive.ics.uci.edu/dataset/264/eeg+eye+state",OTHER,eyeDetection,'1' indicates the eye-closed and '0' the eye-open state.,1,0,utf-8
time_step_classification,5,emg_gestures,EMG Gestures,"For recording patterns, we used a MYO Thalmic bracelet worn on a userÃ¢â‚¬â„¢s forearm, and a PC with a Bluetooth receiver. The bracelet is equipped with eight sensors equally spaced around the forearm that simultaneously acquire myographic signals. The signals are sent through a Bluetooth interface to a PC. We present raw EMG data for 36 subjects while they performed series of static hand gestures.The subject performs two series, each of which consists of six (seven) basic gestures. Each gesture was performed for 3 seconds with a pause of 3 seconds between gestures.",OTHER,class,"the label of gestures (0 - unmarked data, 1 - hand at rest, 2 - hand clenched in a fist, 3 - wrist flexion,4 Ã¢â‚¬â€œ wrist extension, 5 radial deviations, 6 - ulnar deviations, 7 - extended palm (the gesture was not performed by all subjects).)",0,0,utf-8
time_step_classification,6,pamap2,Physical Activity Monitoring,"The PAMAP2 Physical Activity Monitoring dataset contains data of 18 different physical activities, performed by 9 subjects wearing 3 inertial measurement units and a heart rate monitor. The PAMAP2 Physical Activity Monitoring dataset contains data of 18 different physical activities (such as walking, cycling, playing soccer, etc.), performed by 9 subjects wearing 3 inertial measurement units and a heart rate monitor. The dataset can be used for activity recognition and intensity estimation, while developing and applying algorithms of data processing, segmentation, feature extraction and classification. Source: https://archive.ics.uci.edu/dataset/231/pamap2+physical+activity+monitoring",OTHER,activity_id,"1: lying, 2: sitting, 3: standing , 4: walking, 5: running, 6: cycling, 7: Nordic walking, 9: watching TV, 10: computer work, 11: car driving, 12: ascending stairs, 13: descending stairs, 16: vacuum cleaning, 17: ironing, 18: folding laundry, 19: house cleaning, 20: playing soccer, 24: rope jumping, 0: other",1,0,utf-8
time_step_classification,7,multi_frequency_sinusoidal,Multi-Frequency Sinusoidal Signals,"The Multi-Frequency Sinusoidal Signals with Noise Dataset is a synthetic dataset designed for time step classification tasks, particularly in the context of signal processing and frequency classification. It consists of timeseries samples with varying lengths, each composed of segments generated from sinusoidal signals with different frequencies and an additional noise field. Each sample includes continuous observations and corresponding frequency labels for each timestep. The dataset is useful for training and testing machine learning algorithms to develop and evaluate methods for accurately classifying the underlying frequency of signals amidst noise. ",TODO,label,"Categorical target representing one of the 5 frequencies: [0.5, 1.0, 1.5, 2.0, 2.5].",1,1,utf-8
